{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11570251,"sourceType":"datasetVersion","datasetId":7253935}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# MovieLense Rating Data\n<p>CSCA-5632 Unsupervised Algorithms in Machine Learning</p>\n<p>University of Colorado Boulder</p>\n<p>@author alme9155@colorado.edu</p>\n<hr/>\n\n<h2>I. Project Overview:</h2>\n<h3>I.i.Objectives</h3>\n<h3>Use Matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE.</h3> \n\nThis notebook includes the following:\n* Brief EDA procedures\n* Matrix factorization model building and training\n* Model predictions and RMSE results\n* Prediction results comparison with Supervised Learning\n* Improvement from simple baseline.\n\n<h3>I.ii. Project Description</h3>\nThis project will use a MovieLense rating dataset to run matrix factorization model building and return prediction results with root mean square error (RMSE). \n<ul>\n<li>Data source: <a url=\"https://www.kaggle.com/odedgolden/movielens-1m-dataset\">https://www.kaggle.com/odedgolden/movielens-1m-dataset</a></li>\n<li>MovieLens 1M</li>\n</ul>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-26T18:31:59.429227Z","iopub.execute_input":"2025-04-26T18:31:59.429418Z","iopub.status.idle":"2025-04-26T18:32:01.237236Z","shell.execute_reply.started":"2025-04-26T18:31:59.429401Z","shell.execute_reply":"2025-04-26T18:32:01.236539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>II. Exploratory Data Analysis</h2>\n\n<h3>II.i.Loading the data from class CSV files</h3>\nThis notebook includes CSV files from week3 assignment. \n\n<h3>II.ii.Exploring and understanding the data</h3>\nExplore dataset structure.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import coo_matrix, csr_matrix\nfrom scipy.spatial.distance import jaccard, cosine \nfrom pytest import approx\n# EDA process\n# 1. load the dataset\n# 2. inspect the data\n\n## loading the data\nMV_users = pd.read_csv('/kaggle/input/movies-len-1m//users.csv')\nMV_movies = pd.read_csv('/kaggle/input/movies-len-1m//movies.csv')\ntrain = pd.read_csv('/kaggle/input/movies-len-1m//train.csv')\ntest = pd.read_csv('/kaggle/input/movies-len-1m//test.csv')\nprint(f\"Data loaded successfully.\")\n\nprint(f\"\\nTraining Data Info:\")\nprint(\"--------------------------\")\nprint(train.info())\nprint(f\"\\nTesting Data Info:\")\nprint(\"--------------------------\")    \nprint(test.info())\n\nprint(f\"\\nFirst five rows of training data:\")\nprint(\"--------------------------\")    \nprint(train.head())\nprint(f\"\\nFirst five rows of testing data:\")\nprint(\"--------------------------\")    \nprint(test.head())\n\nprint(f\"\\nMissing values in Training Set:\")\nprint(\"--------------------------\")    \nprint(train.isnull().sum())\nprint(f\"\\nMissing Values in Test Set:\")\nprint(\"--------------------------\")    \nprint(test.isnull().sum())\n\n# print(\"\\nArticle Categories\")\n# print(\"--------------------------\")    \n# unique_categories = train['Category'].unique()\n# print(f\"Unique Article categories:{unique_categories}\")\n# print(f\"Number of categories:{len(unique_categories)}\")\n\nfrom collections import namedtuple\nData = namedtuple('Data', ['users','movies','train','test'])\ndata = Data(MV_users, MV_movies, train, test)\n\nprint(\"Resys class loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T18:32:01.238486Z","iopub.execute_input":"2025-04-26T18:32:01.238872Z","iopub.status.idle":"2025-04-26T18:32:03.129247Z","shell.execute_reply.started":"2025-04-26T18:32:01.238843Z","shell.execute_reply":"2025-04-26T18:32:03.128409Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3>II.iii.Create sample train and test dataset for quick debugging</h3>","metadata":{}},{"cell_type":"code","source":"# Creating Sample train data\nnp.random.seed(42)\nsample_train = train[:30000]\nsample_test = test[:30000]\nsample_MV_users = MV_users[(MV_users.uID.isin(sample_train.uID)) | (MV_users.uID.isin(sample_test.uID))]\nsample_MV_movies = MV_movies[(MV_movies.mID.isin(sample_train.mID)) | (MV_movies.mID.isin(sample_test.mID))]\nsample_data = Data(sample_MV_users, sample_MV_movies, sample_train, sample_test)\nprint(f\"Sample train and test dataset created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T17:44:29.223123Z","iopub.execute_input":"2025-04-26T17:44:29.223433Z","iopub.status.idle":"2025-04-26T17:44:29.237283Z","shell.execute_reply.started":"2025-04-26T17:44:29.223411Z","shell.execute_reply":"2025-04-26T17:44:29.236418Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>III. Enhance RecSys class with matrix factorization method</h2>\n\nEnhance Recommendation System class from Week 3 assignment with new method to predict missing ratings from the the test data.","metadata":{}},{"cell_type":"code","source":"from scipy.spatial.distance import pdist, squareform\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n\nclass RecSys():\n    def __init__(self,data):\n        self.data=data\n        self.allusers = list(self.data.users['uID'])\n        self.allmovies = list(self.data.movies['mID'])\n        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n        self.mid2idx = dict(zip(self.data.movies.mID,list(range(len(self.data.movies)))))\n        self.uid2idx = dict(zip(self.data.users.uID,list(range(len(self.data.users)))))\n        self.Mr=self.rating_matrix()\n        self.Mm=None \n        self.sim=np.zeros((len(self.allmovies),len(self.allmovies)))\n        \n    def rating_matrix(self):\n        \"\"\"\n        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n        \"\"\"\n        ind_movie = [self.mid2idx[x] for x in self.data.train.mID] \n        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n        rating_train = list(self.data.train.rating)\n        \n        return np.array(coo_matrix((rating_train, (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies))).toarray())\n\n\n    def predict_everything_to_3(self):\n        \"\"\"\n        Predict everything to 3 for the test data\n        \"\"\"\n        # Generate an array with 3s against all entries in test dataset\n        # your code here\n        return np.full(len(self.data.test), 3.00)\n        \n        \n    def predict_to_user_average(self):\n        \"\"\"\n        Predict to average rating for the user.\n        Returns numpy array of shape (#users,)\n        \"\"\"\n        # Generate an array as follows:\n        # 1. Calculate all avg user rating as sum of ratings of user across all movies/number of movies whose rating > 0\n        # 2. Return the average rating of users in test data\n        # your code here\n        \n        user_average_ratings = self.data.train[self.data.train['rating'] > 0].groupby('uID')['rating'].mean()\n        predicted_rating = self.data.test['uID'].map(user_average_ratings)\n        return predicted_rating\n    \n    def predict_from_sim(self,uid,mid):\n        \"\"\"\n        Predict a user rating on a movie given userID and movieID\n        \"\"\"\n        # Predict user rating as follows:\n        # 1. Get entry of user id in rating matrix\n        # 2. Get entry of movie id in sim matrix\n        # 3. Employ 1 and 2 to predict user rating of the movie\n        # your code here\n        \n        # using the hint given in the resource material:\n        # . ...the sum of similarity scores for all the movies \n        # which were rated by the user-group (i.e. User_rating !=0)\n        \n        user_idx = self.uid2idx[uid]\n        movie_idx = self.mid2idx[mid]\n        \n        user_ratings = self.Mr[user_idx]\n        movie_similarities = self.sim[movie_idx]\n        non_zero_ratings = user_ratings[user_ratings != 0]\n        \n        non_zero_similarities = movie_similarities[user_ratings != 0]\n\n        if np.sum(non_zero_similarities) > 0:\n            weighted_sum = np.dot(non_zero_ratings, non_zero_similarities)\n            similarity_sum = np.sum(non_zero_similarities)\n            predicted_rating = weighted_sum / similarity_sum\n        else:\n            if len(non_zero_ratings) > 0:\n                predicted_rating = np.mean(non_zero_ratings) \n            else:\n                predicted_rating = 3.0            \n        return predicted_rating\n    \n    \n    \n    def predict(self):\n        \"\"\"\n        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n        \"\"\"\n        # your code here\n        # no normalization needed because predict_from_sim already filter out zero values\n        predicted_ratings = []\n        for _, row in self.data.test.iterrows():\n            predicted_result_from_sim = self.predict_from_sim(row['uID'] , row['mID'])\n            predicted_ratings.append(predicted_result_from_sim)\n            \n            #user_avg = self.Mr[self.uid2idx[uid]].mean() \n            #normalized_predicted_rating = predicted_result_from_sim - user_avg\n            #predicted_ratings.append(normalized_predicted_rating)            \n        return np.array(predicted_ratings)\n        \n    \n    def rmse(self,yp):\n        yp[np.isnan(yp)]=3 #In case there is nan values in prediction, it will impute to 3.\n        yt=np.array(self.data.test.rating)\n        return np.sqrt(((yt-yp)**2).mean())\n\n\n    def predict_from_matrix_factorization(self, model):\n        \"\"\"\n        Predict ratings for the test set using matrix factorization model\n        \n        Parameters:\n        model: A matrix factorization model \n        \n        Returns:\n        predicted_ratings: A numpy array of predicted ratings for the test set.\n        \"\"\"\n        # Fit the model on the training rating matrix\n        Mr = self.Mr\n        user_matrix = model.fit_transform(Mr)      # Matrix (#users, #components)\n        item_matrix = model.components_            # Matrix (#components, #movies)\n\n        # Predict the full reconstructed ratings\n        Mr_pred = np.dot(user_matrix, item_matrix)\n        \n        mean_rating = 3.0\n        if self.data.train['rating'].size > 0:\n            mean_rating = self.data.train['rating'].mean() \n\n        predicted_ratings = []\n        for idx, row in self.data.test.iterrows():\n            uid = row['uID']\n            mid = row['mID']\n\n            # Check if user and movie exist in training data\n            yp = mean_rating\n            if uid in self.uid2idx and mid in self.mid2idx:\n                user_idx = self.uid2idx[uid]\n                movie_idx = self.mid2idx[mid]\n                yp = Mr_pred[user_idx, movie_idx]\n                yp = np.clip(yp, 1, 5)\n\n            predicted_ratings.append(yp)\n        return np.array(predicted_ratings)\n\nprint(f\"Enhanced RecSys with predict_from_matrix_factorization loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T19:40:43.612662Z","iopub.execute_input":"2025-04-26T19:40:43.613206Z","iopub.status.idle":"2025-04-26T19:40:43.627354Z","shell.execute_reply.started":"2025-04-26T19:40:43.613184Z","shell.execute_reply":"2025-04-26T19:40:43.626640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Content Based filtering and Collaborative filtering\nclass ContentBased(RecSys):\n    def __init__(self,data):\n        super().__init__(data)\n        self.data=data\n        self.Mm = self.calc_movie_feature_matrix()  \n        \n    def calc_movie_feature_matrix(self):\n        \"\"\"\n        Create movie feature matrix in a numpy array of shape (#allmovies, #genres) \n        \"\"\"\n        # your code here\n        movie_feature_matrix = self.data.movies[self.genres].values\n        return csr_matrix(movie_feature_matrix)\n    \n    \n    def calc_item_item_similarity(self):\n        \"\"\"\n        Create item-item similarity using Jaccard similarity\n        \"\"\"\n        # Update the sim matrix by calculating item-item similarity using Jaccard similarity\n        # Jaccard Similarity: J(A, B) = |A∩B| / |A∪B| \n        # your code here\n        # using functions in the scipy.spatial.distance to speed up calculation\n        # jaccard similiarity = 1 - jaccard_distance \n        jaccard_distances = pdist(self.Mm.toarray(), 'jaccard')  \n        self.sim = 1 - squareform(jaccard_distances)\n        \n                \nclass Collaborative(RecSys):            \n    def calc_item_item_similarity(self, simfunction, *X):  \n        \"\"\"\n        Create item-item similarity using similarity function. \n        X is an optional transformed matrix of Mr\n        \"\"\"    \n        # General function that calculates item-item similarity based on the sim function and data inputed\n        if len(X)==0:\n            self.sim = simfunction()            \n        else:\n            self.sim = simfunction(X[0]) # *X passes in a tuple format of (X,), to X[0] will be the actual transformed matrix\n            \n    def cossim(self):    \n        \"\"\"\n        Calculates item-item similarity for all pairs of items using cosine similarity (values from 0 to 1) on utility matrix\n        Returns a cosine similarity matrix of size (#all movies, #all movies)\n        \"\"\"\n        # Return a sim matrix by calculating item-item similarity for all pairs of items using Jaccard similarity\n        # Cosine Similarity: C(A, B) = (A.B) / (||A||.||B||) \n        # your code here\n        # Using the hint:\n        #  \"Impute the unrated entries in self.Mr to the user's average rating\n        #.     then subtract by the user mean, call this matrix X.\"\n        \n        user_means = np.nanmean(np.where(self.Mr != 0, self.Mr, np.nan), axis=1, keepdims=True)\n        Mr_imputed = np.where((self.Mr == 0), user_means, self.Mr)          \n        Xr = Mr_imputed - user_means\n        \n        Xr = np.nan_to_num(Xr, nan=0.0)        \n        Xr_sparse = csr_matrix(Xr.T)\n        self.sim = 0.5 * (1+cosine_similarity(Xr_sparse))\n        np.fill_diagonal(self.sim, 1)      \n        Xr = Mr_imputed - user_means \n        if np.isnan(Xr).any():\n            Xr = np.nan_to_num(Xr)\n\n        num_items = Xr.shape[1]\n        self.sim = np.zeros((num_items, num_items))\n        for i in range(num_items):\n            for j in range(i, num_items):\n                if i == j:\n                    self.sim[i, j] = 1\n                else:\n                    dist = cosine(self.Mr[:, i], self.Mr[:, j])\n                    self.sim[i, j] = 1 - dist\n                    self.sim[j, i] = 1 - dist\n        self.sim = np.clip(self.sim, 0, 1)\n        return self.sim\n\n        \n    def jacsim(self,Xr):\n        \"\"\"\n        Calculates item-item similarity for all pairs of items using jaccard similarity (values from 0 to 1)\n        Xr is the transformed rating matrix.\n        \"\"\"    \n        # Return a sim matrix by calculating item-item similarity for all pairs of items using Jaccard similarity\n        # Jaccard Similarity: J(A, B) = |A∩B| / |A∪B| \n        # your code here\n        # ref: https://docs.scipy.org/doc/scipy-1.12.0/reference/generated/scipy.spatial.distance.pdist.html\n        Xr = csr_matrix(Xr)\n        \n        Xr = (Xr != 0).astype(int)\n        jaccard_distances = pairwise_distances(Xr.T.toarray(), metric='jaccard')\n        self.sim = 1 - jaccard_distances\n        np.fill_diagonal(self.sim, 1)\n        self.sim = np.clip(self.sim, 0, 1)\n        return self.sim\n\nprint(f\"Similiarity measure loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T19:40:47.769119Z","iopub.execute_input":"2025-04-26T19:40:47.769428Z","iopub.status.idle":"2025-04-26T19:40:47.779661Z","shell.execute_reply.started":"2025-04-26T19:40:47.769406Z","shell.execute_reply":"2025-04-26T19:40:47.779027Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>IV. Baseline and Similiarity Predictions</h2>","metadata":{}},{"cell_type":"code","source":"# From week 3 assignment\nrs = RecSys(data)\nyp_everything_to_3 = rs.predict_everything_to_3()\nrmse_everything_to_3 = rs.rmse(yp_everything_to_3)\nprint(f\"Predict Everything to 3: RMSE=:{rmse_everything_to_3}\")\nyp_to_user_average = rs.predict_to_user_average()\nrmse_to_user_average = rs.rmse(yp_to_user_average)\nprint(f\"Predict to User Average: RMSE=:{rmse_to_user_average}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T18:34:31.683843Z","iopub.execute_input":"2025-04-26T18:34:31.684353Z","iopub.status.idle":"2025-04-26T18:34:32.408478Z","shell.execute_reply.started":"2025-04-26T18:34:31.684325Z","shell.execute_reply":"2025-04-26T18:34:32.407703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Content based filtering\ncb = ContentBased(data)\ncb.calc_item_item_similarity()\nyp_cb = cb.predict()\nrmse_content_based = cb.rmse(yp_cb)\nprint(f\"Predict using Content-based filtering: RMSE=:{rmse_to_user_average}\")\n\n# Collaborative filtering\n# cosine similiarity\ncf = Collaborative(data)\ncf.calc_item_item_similarity(cf.cossim)\nyp_cossim = cf.predict()\nrmse_cosine = cf.rmse(yp_cossim)\nprint(f\"Predict using Cosine Similiarity: RMSE=:{rmse_to_user_average}\")\n\n# jaccard similiarity \nXr = cf.Mr.astype(int)\nt0=time.perf_counter()\ncf.calc_item_item_similarity(cf.jacsim,Xr)\nt1=time.perf_counter()\ntime_sim = t1-t0\nprint('similarity calculation time',time_sim)\nyp = cf.predict()\nrmse_jasim = cf.rmse(yp)\nprint(f\"Predict using Jaccard Similarity: RMSE=:{rmse_jasim}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T19:41:21.133186Z","iopub.execute_input":"2025-04-26T19:41:21.133721Z","iopub.status.idle":"2025-04-26T19:48:39.396675Z","shell.execute_reply.started":"2025-04-26T19:41:21.133696Z","shell.execute_reply":"2025-04-26T19:48:39.396063Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>V. NMF Predictions with static hyper-parameter</h2>","metadata":{}},{"cell_type":"code","source":"# NMF prediction with n_component =20\nfrom sklearn.decomposition import NMF\n\nclf = NMF(n_components=20)\npredicted_ratings = rs.predict_from_matrix_factorization(clf)\nrmse_nmf_20 = rs.rmse(predicted_ratings)\nprint(f\"Matrix Factorization (n_components=20): RMSE: {rmse_nmf_20:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T19:02:56.426913Z","iopub.execute_input":"2025-04-26T19:02:56.427647Z","iopub.status.idle":"2025-04-26T19:03:17.256424Z","shell.execute_reply.started":"2025-04-26T19:02:56.427622Z","shell.execute_reply":"2025-04-26T19:03:17.255716Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>VI. Hyper-parameter tuning</h2>","metadata":{}},{"cell_type":"code","source":"# hyper-parameter tuning to find best n_component, and lowest RMSE value\nfrom sklearn.decomposition import NMF\n\nn_component_values = [5, 10, 15, 20, 30, 40, 50]\nrmse_values = []\n\nbest_nmf_comp =0\nbest_nmf_rmse= np.inf\n\nfor comp in n_component_values:\n    clf = NMF(n_components=comp)\n    predicted_ratings = rs.predict_from_matrix_factorization(clf)\n    true_ratings = np.array(rs.data.test['rating'])\n    rmse = rs.rmse(predicted_ratings)    \n    print(f\"n_components = {comp}, RMSE = {rmse:.3f}\")\n    if rmse < best_nmf_rmse:\n        best_nmf_rmse = rmse\n        best_nmf_comp = comp\n    rmse_values.append(rmse)\n    \nprint(f\"Best RMSE value with NMF prediction(n_components = {best_nmf_comp}), RMSE = {best_nmf_rmse:.3f}\")\nplt.figure(figsize=(8,6))\nplt.plot(n_component_values, rmse_values, marker='o')\nplt.title('RMSE vs. n_components for NMF')\nplt.xlabel('Number of Components (n_components)')\nplt.ylabel('RMSE')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T19:08:45.963555Z","iopub.execute_input":"2025-04-26T19:08:45.964097Z","iopub.status.idle":"2025-04-26T19:12:04.410413Z","shell.execute_reply.started":"2025-04-26T19:08:45.964076Z","shell.execute_reply":"2025-04-26T19:12:04.409690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# show comparison of RMSE vs Methods.\nmethods = [\n    'Predict Everything to 3',\n    'Predict to User Average',\n    'Content-Based Filtering',\n    'Collaborative Filtering (Cosine)',\n    'Collaborative Filtering (Jaccard)',\n    f\"Matrix Factorization (NMF)(n_comp={best_nmf_comp})\"\n]\n\nrmse_values = [\n    rmse_everything_to_3,\n    rmse_to_user_average,\n    rmse_content_based,\n    rmse_cosine,\n    rmse_jasim, \n    best_nmf_rmse\n]\nrmse_df = pd.DataFrame({\n    'Method': methods,\n    'RMSE': rmse_values\n})\nrmse_df_sorted = rmse_df.sort_values('RMSE').reset_index(drop=True)\n\nplt.figure(figsize=(10,6))\nplt.barh(methods, rmse_values)\nplt.xlabel('RMSE')\nplt.title('Comparison of Error using Different Recommendation Methods')\nplt.gca().invert_yaxis() \nplt.grid(axis='x')\nplt.show()\n\ndisplay(rmse_df_sorted)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T19:50:07.419602Z","iopub.execute_input":"2025-04-26T19:50:07.419884Z","iopub.status.idle":"2025-04-26T19:50:07.577874Z","shell.execute_reply.started":"2025-04-26T19:50:07.419862Z","shell.execute_reply":"2025-04-26T19:50:07.577036Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2>VII. Conclusion</h2>\n\n<p><b>Prediction results comparison using RMSE measure</b></p>\n\n<p>Comparing the prediction results, unsupervised method using NMF performs significantly worse than other methods returns highest RMSE error.</p>\n<p><b>Analysis: </b>Since the MovieLens-1M dataset is extremely sparse, the RMSE ~2.5 values suggest that the zeros values should be reconstructed as low values. Failing to ignore zeros during factorization can distort the learned latent factors.</p>\n<p><b>Possible improvement: </b>If we mask out the components from the unknown values, prediction from NMF could be better. This could potentially be better than \"everything to 3\", but it will still be worse than a similarity-based method. </p>","metadata":{}},{"cell_type":"markdown","source":"@author alme9155@colorado.edu<br/>\n@url: https://www.kaggle.com/code/ameau01/movierecommender-system-with-matrix-factorization","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":".","metadata":{}}]}